# 데이터 동기화 처리를 위한 Apache Kafka

---

## Kafka를 사용하는 이유
- 모든 시스템으로 데이터를 실시간으로 전송하여 처리할 수 있는 시스템
- 데이터가 많아지더라도 **확장이 용이한 시스템**
- 데이터를 보내는 쪽과 받는 쪽은 누가 보냈고 생성했는지에 대해 신경쓰지 않아도 된다.


---

## Apache Kafka 특징
- Producer / Consumer 분리
- 메세지를 여러 Consumer에게 허용한다.
- 높은 처리량을 위해 메시지 최적화시켜서 내부적으로 보관한다.
- Scale-out 가능
- Eco-system

---

## Kafka Broker
- Kafka 애플리케이션 서버
- 3대 이상의 Broker Cluster 구성을 권장한다.(실무)
- Zookeeper 연동
  - 서버의 상태를 중재, 관리해주는 코디네이터 역할
  - 역할: 메타데이터(ID) 저장, Controller 정보 저장
- n개의 Broker중 1대는 Controller 기능을 수행한다.

---

## Apache Kafka 사용(v2.8.1)
### Ecosystem 1 - Kafka Client
- Kafka와 데이터를 주고받기 위해 사용하는 Java Library
- Producer, Consumer, Admin, Stream 등 Kafka 관련 API 제공
- 다양한 3rd party library 존재

### Kafka 서버 기동
- zookeeper 및 kafka 서버 구동
  - `$KAFKA_HOME/bin/windows/zookeeper-server-start.bat` `$KAFKA_HOME/config/zookeeper.properties`
  - `$KAFKA_HOME/bin/windows/kafka-server-start.bat` `$KAFKA_HOME/config/server.properties`
- topic 생성
  - `$KAFKA_HOME/bin/windows/kafka-topics.bat --create --topic quickstart-events --bootstrap-server localhost:9092 --partitions 1`
    - `--bootstrap-server localhost:9092`: 9092 포트를 사용하는 카프카 서버에 토픽을 생성(카프카 서버의 기본 포트는 9092)
    - `--partitions 1`: 멀티 클러스터링을 사용할 경우 파티션을 나누기 위해 사용한다. 
- Topic 목록 확인
  - `$KAFKA_HOME/bin/windows/kafka-topics.bat --bootstrap-server localhost:9092 --list`
- Topic 정보 확인
  - `$KAFKA_HOME/bin/windows/kafka-topics.bat --describe --topic quickstart-events --bootstrap-server localhost:9092`

> 참고 <br>
> Mac 환경에서는 `$KAFKA_HOME/bin/windows/kafka-topics.bat` 대신 `$KAFKA_HOME/bin/kafka-topics.sh`를 사용해주면 된다. <br>
> Windows cmd 환경에서 실습할 때는 `$KAFKA_HOME\bin\windows\kafka-topics.bat`으로 작성

<br>

- 메시지 생산
  - `$KAFKA_HOME/bin/windows/kafka-console-producer.bat --broker-list localhost:9092 --topic quickstart-events`

![kafka-produce](img/kafka1.png)

<br>

- 메시지 소비
  - `$KAFKA_HOME/bin/windows/kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic quickstart-events --from-begining`
    - `--from-begining`: 메세지를 처음부터 받아온다.

![kafka-consume](img/kafka2.png)

<br>

### Ecosystem 2 - Kafka Connect
- Kafka Connect를 사용하면 Data를 통해 Import/Export 가능
- 코드 없이 Configuration으로 데이터 이동
- Standalone mode, Distribution mode 지원
  - Restful API를 통해 지원
  - Stream 또는 Batch 형태로 데이터 전송 가능
  - 커스텀 Connector를 통한 다양한 Plugin 제공(S3, Hive, Mysql)

### Kafka Connect 사용을 위한 MariaDB 설치
#### MacOS
- 설치: `$ brew install mariadb`
- 시작, 종료, 상태 확인: `$ mysql.server start`, `$ mysql.server stop`, `$ mysql.server status`
- 접속: `$ mysql-u root`
- 데이터 베이스 생성: `create database mydb`

<br>

> Access denied 발생 시 <br>
> - `$ sudo mysql -u root`
> - `mysql> use mysql`
> - `select user, host, plugin FROM mysql.user`
> - `set password for 'root'@'localhost'=password('test1357');`
> - `flush privileges;` (변경 사항 반영)

<br>

#### Windows
- MariaDB 공식 사이트에서 다운로드
- cmd 실행 후 데이터 베이스 초기화
  
```
.\bin\mariadb-install-db.exe
  --datadir=C:\{원하는 경로}\mariadb-10.5.8-winx64\data
  --service=mariaDB
  --port=3306
  --password=test1357
```

<br>

> HeidiSQL을 활용해서 실행하는 방법도 있다.

<br>

### OrderService에서 MariaDB 연동
#### Dependency 추가
```xml
<dependency>
    <groupId>org.mariadb.jdbc</groupId>
    <artifactId>mariadb-java-client</artifactId>
    <version>2.7.2</version>
</dependency>
```


